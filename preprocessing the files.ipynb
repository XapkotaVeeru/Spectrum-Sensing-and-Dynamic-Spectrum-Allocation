{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-12-30T07:44:42.869458Z",
     "start_time": "2025-12-30T07:44:42.392746Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "buf = 1024  # Must match buffer size used when converting .bin to HDF5\n",
    "test_size = 0.1  # Fraction of data to use as test set\n",
    "seed = 42  # Random seed for reproducibility\n",
    "\n",
    "# Path containing the HDF5 files generated from SDR .bin files\n",
    "h5_folder_fp = \"/Users/biratsapkota/Downloads/supported-format-files/\"\n",
    "folder = os.listdir(h5_folder_fp)\n",
    "folder.sort()\n",
    "\n",
    "print(f\"Found {len(folder)} files in {h5_folder_fp}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 32 files in /Users/biratsapkota/Downloads/supported-format-files/\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T07:44:51.842852Z",
     "start_time": "2025-12-30T07:44:51.840424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize arrays to store full dataset and labels\n",
    "dataset = np.zeros((1, buf, 2), dtype='f')        # shape: (samples, buf, 2)\n",
    "dataset_labels = np.zeros((1, 4), dtype='i')      # shape: (samples, num_classes)\n",
    "\n",
    "print(\"Initialized empty dataset arrays.\")\n"
   ],
   "id": "75dd7dbe9ff126e6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized empty dataset arrays.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T07:45:03.527934Z",
     "start_time": "2025-12-30T07:44:59.812442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for file in folder:\n",
    "    file_path = os.path.join(h5_folder_fp, file)\n",
    "\n",
    "    if os.path.isfile(file_path) and file.endswith(\".h5\"):\n",
    "        # Open HDF5 file\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            name = os.path.splitext(file)[0]\n",
    "            data = f[name][()]\n",
    "\n",
    "        print(f\"Loaded {data.shape[0]} samples from {file}\")\n",
    "\n",
    "        # Append data to dataset\n",
    "        dataset = np.concatenate((dataset, data), axis=0)\n",
    "\n",
    "        # Generate labels from filename\n",
    "        # Assumes filename starts with multi-hot label like '1010_filename.h5'\n",
    "        label_str = name.split('_')[0]\n",
    "        label = [int(c) for c in label_str]\n",
    "        label = np.array([label] * data.shape[0], dtype='i')  # Repeat label for each sample\n",
    "        dataset_labels = np.concatenate((dataset_labels, label), axis=0)\n"
   ],
   "id": "6d13b1ea8ba8c082",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3905 samples from 0000_day1.h5\n",
      "Loaded 3905 samples from 0000_day2.h5\n",
      "Loaded 3905 samples from 0001_day1.h5\n",
      "Loaded 3905 samples from 0001_day2.h5\n",
      "Loaded 3905 samples from 0010_day1.h5\n",
      "Loaded 3905 samples from 0010_day2.h5\n",
      "Loaded 3905 samples from 0011_day1.h5\n",
      "Loaded 3905 samples from 0011_day2.h5\n",
      "Loaded 3905 samples from 0100_day1.h5\n",
      "Loaded 3905 samples from 0100_day2.h5\n",
      "Loaded 3905 samples from 0101_day1.h5\n",
      "Loaded 3905 samples from 0101_day2.h5\n",
      "Loaded 3905 samples from 0110_day1.h5\n",
      "Loaded 3905 samples from 0110_day2.h5\n",
      "Loaded 3905 samples from 0111_day1.h5\n",
      "Loaded 3905 samples from 0111_day2.h5\n",
      "Loaded 3905 samples from 1000_day1.h5\n",
      "Loaded 3905 samples from 1000_day2.h5\n",
      "Loaded 3905 samples from 1001_day1.h5\n",
      "Loaded 3905 samples from 1001_day2.h5\n",
      "Loaded 3905 samples from 1010_day1.h5\n",
      "Loaded 3905 samples from 1010_day2.h5\n",
      "Loaded 3905 samples from 1011_day1.h5\n",
      "Loaded 3905 samples from 1011_day2.h5\n",
      "Loaded 3905 samples from 1100_day1.h5\n",
      "Loaded 3905 samples from 1100_day2.h5\n",
      "Loaded 3905 samples from 1101_day1.h5\n",
      "Loaded 3905 samples from 1101_day2.h5\n",
      "Loaded 3905 samples from 1110_day1.h5\n",
      "Loaded 3905 samples from 1110_day2.h5\n",
      "Loaded 3905 samples from 1111_day1.h5\n",
      "Loaded 3905 samples from 1111_day2.h5\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T07:45:12.779636Z",
     "start_time": "2025-12-30T07:45:12.570026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset, dataset_labels, test_size=test_size, random_state=seed\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n"
   ],
   "id": "fa97bdd50c6111b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 112464 samples\n",
      "Test set: 12497 samples\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T07:45:19.976786Z",
     "start_time": "2025-12-30T07:45:19.902791Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with h5py.File('./sdr_test.hdf5', 'w') as f_test:\n",
    "    f_test.create_dataset('X', data=X_test, dtype='f')\n",
    "    f_test.create_dataset('y', data=y_test, dtype='i')\n",
    "\n",
    "print(\"Saved test set: sdr_test.hdf5\")\n"
   ],
   "id": "bad3c6e2d71b44f6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved test set: sdr_test.hdf5\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-30T07:45:26.993578Z",
     "start_time": "2025-12-30T07:45:26.515445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with h5py.File('./sdr_train.hdf5', 'w') as f_train:\n",
    "    f_train.create_dataset('X', data=X_train, dtype='f')\n",
    "    f_train.create_dataset('y', data=y_train, dtype='i')\n",
    "\n",
    "print(\"Saved training set: sdr_train.hdf5\")\n"
   ],
   "id": "c78a6a3af6f6b9e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved training set: sdr_train.hdf5\n"
     ]
    }
   ],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
